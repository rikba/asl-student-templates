\chapter{Controls}
\label{sec:controls}
The cascaded multirotor control with decoupled attitude and position control as depicted in figure \ref{pics:controller_sketch} is a popular structure. Both nonlinear and linear control schemes have been proposed for this. These include integral backstepping, sliding mode, geometric control, PID control, learning control, mathematical optimization or combinations of these.

Bouabdallah formulated integral backstepping and sliding mode control \cite{Bouabdallah2005,Bouabdallah2007}. Lee developed a geometric tracking control \cite{Lee2010}. Hoffmann et. al. used PID control for their STARMAC quadrotor \cite{Hoffmann2007}. Robust $H_\infty$ control gives the ability guarantee stability even with model uncertainties. E.g. Felix Bergenkamp used Gaussian learning to determine uncertainty and then used $H_\infty$ to control a quadrotor \cite{Berkenkamp2014,www:robustquad}. Model predictive control schemes become more spread in multirotor control. Tzes, Nikolakopoulos and Alexis build a full linear MPC for a quadrotor \cite{Tzes2012}. Burri developed a decoupled MPC for position control \cite{Burri2012}. 

We decide to go with the mathematical optimization techniques and will derive a LQR with integrator, a linear offset-free MPC and a nonlinear MPC with integrator for general multirotor platforms. 

In this section, the advantages and disadvantages of the proposed controllers will be stated. Then the general problem formulation is presented and how it is adapted to our problem. The algorithms will then be tested in the proposed MATLAB simulator and compared.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LQRI
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{LQRI} 
LQR is a mathematical optimization based control technique for linear control systems with quadratic cost functions. The controller is straight forward to tune, easy applicable for multiple input multiple output (MIMO), guarantees stability for the given linearized system and is optimal with respect to the system representation and cost function. Further, the gain matrix $K$ can be computed offline, such that applying the control law reduces to a simple matrix multiplication.

\subsection{Problem Formulation}
Given a discrete-time linear system with infinite-time quadratic cost
\begin{align}
x_{k+1} &= Ax_k + Bu_k \label{eq:lqr_system_x}\\
J(u_0,u_1,...,u_\infty) &= \sum_{k=0}^\infty  x_k^TQx_k + u_k^TRu_k \label{eq:lqr_system_J}
\end{align} 
with $(A,B)$ stabilizable, $(A,G)$ with $Q= G G^T$ controllable, weighting matrices $R\succ0$ positive definite and $Q\succeq0$ positive semi-definite, one can find a unique, stabilizing, linear state-feedback control law $u(k) = -{K} x(k)$, that minimizes the quadratic cost.
This law is found solving the discrete-time algebraic Riccati equation (DARE) for $x$.
\begin{align}
{A}^Tx{A}  - {A}^T x {B} \left( {B}^T x {B} + {R} \right)^{-1} {B}^T x^T {A} + {Q} = 0 \\
{K} = \left( {B}^T x {B} + {R} \right)^{-1} {B}^T x {A}
\end{align}

For offset-free reference tracking the system \ref{eq:lqr_system_x} is augmented by an integrator state $e$.
\begin{align}
e_{k+1} = e_k + {T_s} \left( r_k - {H}x_k \right) \label{eq:lqr_system_e}
\end{align}
$r_k$ is the reference to be tracked, ${H}x_k$ is the corresponding state and $T_s$ is the sampling time.

More details on LQR/LQRI control, the solution of the algebraic Riccati equation, stability and tuning can be obtained in Anderson and Moore \cite{Anderson2007}.

\subsection{Implementation}
The proposed LQRI controller has been implemented in MATLAB. The controller gain matrix $\mathbf{K}$ is found using the function \texttt{lqi}, which takes as arguments the system equations and weighting matrices and solves the DARE. The gain needs to be established only once in the initialization. While the controller is running, the control input is found via
\begin{align}
u(k) = \mathbf{K} x(k).
\end{align}

Since the position and velocity state estimations and reference position come in world-coordinates from the sensor fusion, these have to be transformed to orientation-fixed frame first, before applying the control law. Also the control input, which is according to the formulation \ref{eq:lqri_u} relative to the hovering input, needs to be transformed, before returning it to the system. Algorithm \ref{alg:lqri} illustrates the described simulation.

The controller gain is obtained in the initialization phase. When calling the controller, the transformations into orientation-fixed frame are done, the control law is applied, the reference heading set to the desired heading and the calculated thrust input is transformed.
\input{algorithms/lqri_control.tex}
\subsubsection{System Dynamics}
Having set up the linear state-space model \ref{eq:lin_sys_dt}--\ref{eq:lin_sys_y}, the LQRI formulation is almost obtained. The system has to be discretized with respect the position control sampling time $Ts=0.01\si{\second}$ and augmented with an integrator state .We will not model the effects of wind. Here, the integrator has to compensate offsets due to wind. 

In the general equations \ref{eq:lqr_system_x}, \ref{eq:lqr_system_J}, \ref{eq:lqr_system_e} we substitute the variables from our multirotor problem derived in the modeling section \ref{sec:modeling}. The system matrices, inputs and states can be taken directly. As reference we take the desired position in orientation-fixed frame. The $H$ matrix is chosen accordingly.
\begin{align}
{A} &\gets {\mathbf{A}} \\
{B} &\gets {\mathbf{B}} \\
x_k &\gets \begin{bmatrix}
{\mathbf{x}}_k - \mathbf{x}_{\mathcal{O},ss} \\
e_k
\end{bmatrix} \\
u_k &\gets \orientation{\mathbf{u}}_k - \mathbf{u}_{\mathcal{O},ss} \label{eq:lqri_u}\\
r_k &\gets \mathbf{r}_{\mathcal{O},ref,k} \\
{H} &\gets \begin{bmatrix}
\mathbf{0}_{3\times4} & \mathbf{I}_3 & \mathbf{0}_{3\times3}
\end{bmatrix} 
\end{align}

\begin{remark}
An alternative approach could have been to linearize the system at every sample instant about the current state instead about hovering. However, this requires for the DARE to be solved at every instant. This is for example done at a high rate in rocket control by Cimen \cite{Cimen2008}.
\end{remark}

\subsubsection{Weights}
For reference tracking the error term $e_k$ has to be minimized. This means, that we have to penalize it in the cost function. Because we want a fast response, we do not penalize the other states. On the other hand, we will apply some weight to the inputs in order to fulfill the criterion ${R}\succ0$ and bound the inputs. Hence, after some adjustment, the following weighting matrices ${Q} \in \mathbb{R}^{13\times13}$ and ${R} \in \mathbb{R}^{3\times3}$ have been chosen for the Firefly. 
\begin{align}
\mathbf{Q} &= \begin{bmatrix}
\mathbf{0}_{10\times10} & \mathbf{0}_{10\times3} \\
\mathbf{0}_{3\times10} & \mathbf{I}_{3} 
\end{bmatrix} \\
\mathbf{R} &= \begin{bmatrix}
0.01 & 0 & 0 \\
0 & 0.3 & 0 \\
0 & 0 & 0.3
\end{bmatrix}
\end{align}

%\begin{align}
%\orientation{\mathbf{x}}(k+1) &= \discrete{\mathbf{A}} \orientation{\mathbf{x}}(k) + \discrete{\mathbf{B}} \orientation{\mathbf{u}}(k) \\
%\mathbf{e}(k+1) &= \mathbf{e}(k) + T_s \left( \mathbf{r}_{\mathcal{O},ref}(k) - \mathbf{H}\orientation{\mathbf{x}}(k) \right) \\
%\mathbf{H} &= \begin{bmatrix}
%\mathbf{0}_{3\times4} & \mathbf{I}_3 & \mathbf{0}_{3\times3} \\
%J &= \sum_{k=0}^\infty  x(k)^T\mathbf{Q}x(k) + u(k)^T\mathbf{R}u(k)
%\end{bmatrix}
%\end{align}




\subsection{Simulation Results}
To validate the controller's quality, we perform various experiments using the MATLAB simulator proposed above. First, we will determine the performance. Then we will check its ability to follow dynamic references. Next we will see how it reacts to measurement noise. Finally, a wind experiment is performed.

\subsubsection{Performance}
In order to determine the performance of the LQRI, we run a noise-free step experiment. The reference is set $1 \si{\metre}$ away from the MAV into $x$--direction. The LQRI then finds appropriate input signals for the multirotor to move to this position from hovering. Figure \ref{fig:lqri_step} depicts the outcome of this experiment.
\begin{figure}
\centering
\subfloat[][{Position output}]{
\includegraphics{\folder/tikzfigures/step_response_out_lqri.tikz}
\label{fig:lqri_step_out}}
\qquad
\subfloat[][{Control input}]{
\includegraphics{\folder/tikzfigures/step_response_in_lqri.tikz}
\label{fig:lqri_step_in}}
\caption{Simulated unit step response of the LQRI controlled Firefly. The MAV has to fly from hovering $1\si{\metre}$ ahead.}
\label{fig:lqri_step}
\end{figure}

The step response shows a typical integrator action. It overshoots the targeted position but then settles to the desired value. The hexacopter has a $10$ to $90\si{\percent}$ rise time of $0.91 \si{\second}$ and a $2\si{\percent}$ settling time of $2.76 \si{\second}$. Also it overshoots about $7 \si{\centi\metre}$.

The control inputs \ref{fig:lqri_step_in} show typical LQRI behavior. In the first interval the multirotor pitches towards the desired target position. Then at some point on its way it pitches back into the opposite direction to slow down the MAV. This repeats until the integral error has diminished. 

The thrust is decreased in the first interval in order to pitch faster. Next the hexacopter increases the thrust slightly, before it eventually has settled and the thrust returns to steady-state.

In the output \ref{fig:lqri_step_out} one can notice, that the MAV is slightly losing height in the driving phase from $0.5$ to $1.5 \si{\second}$. %This could come from the fact, that the modeled rotor drag is lost in $z$--direction during linearization as it is higher order (see system matrix in \ref{eq:system_matrix}).

\subsubsection{Delay}
In this experiment, we want to show the LQRI's behavior when opposed to non-constant references. Again we run a noise free experiment. This time the MAV has to go forwards and backwards $1\si{\metre}$ twice within $6 \si{\second}$, which corresponds to following a sine trajectory.

One can observe two issues, when following the sine reference (see figure \ref{fig:lqri_sine}). First the MAV does not reach the full amplitude. Second it reaches its amplitude with some delay.

The multirotor not reaching the full amplitude comes from the rather ambitious reference trajectory. The LQRI is not able to follow such fast changes, as can be inferred from the response time in the step experiment.

The second issue of having some delay comes on the one hand from the too slow close loop dynamics as stated before, and on the other hand from missing future knowledge. At every sample instant, the LQRI only knows, that it has to reach the very next reference point. In the infinite horizon optimal control problem, the solver assumes, that the MAV shall hover at this point. It does not know, that it has to keep going after reaching the position.

One could reduce the latter problem of delay by giving some more information to the controller, e.g. feed a reference velocity or have some other means of feed-forward control.

\begin{figure}
\centering
\includegraphics{\folder/tikzfigures/sine_response_out_LQRI.tikz}
\caption{Simulated sine trajectory experiment  of the LQRI controlled Firefly. The MAV has to fly back and forth $1\si{\metre}$ starting from hovering. }
\label{fig:lqri_sine}
\end{figure} 

\subsubsection{Noise}
While the two experiments before have been noise free, in the real environment, the state measurement will always be corrupted by noise. Therefore, we will examine the effect of noise. We assume typical additive white noise and some delay on the states as proposed in the MATLAB simulator section \ref{sec:matlab_simulator_noise}.

We repeat the step experiment with additive noise about the position, velocity, angle and angular rate measurement. The magnitude is according to the Firefly's IMU and the Vicon specifications. The resulting step response with the according input can be seen in figure \ref{fig:lqri_step_noisy}.

The noise is directly forwarded to the control input. What has been a smooth control signal in the noise free experiment \ref{fig:lqri_step_in} is now scrambled \ref{fig:lqri_step_in_noisy}. This lead to some undesired shaking or jerk of the MAV and is increased if the LQRI gain was increased. However, with this setup, the position tracking is still satisfied, and the controller remains stable.

\begin{figure}
\centering
\subfloat[][{Position output}]{
\includegraphics{\folder/tikzfigures/step_response_out_LQRI_noisy.tikz}
\label{fig:lqri_step_out_noisy}}
\qquad
\subfloat[][{Control input}]{
\includegraphics{\folder/tikzfigures/step_response_in_LQRI_noisy.tikz}
\label{fig:lqri_step_in_noisy}}
\caption{Unit step response LQRI with noisy state measurements.}
\label{fig:lqri_step_noisy}
\end{figure}

\subsubsection{Wind}
In the LQRI wind is not explicitly modeled. Instead, it has to rely on the integral action to compensate offset due to wind. We simulate the following experiment:

The MAV has to climb up linearly from $0$ to $20 \si{\metre}$ at $0.15 \si{\metre\per\second}$ in a helix like manner. While climbing up it has to complete $4$ circles with a diameter of $4\si{\metre}$. The whole experiment takes $1 \si{\minute}$. 

From $5$ to $15 \si{\metre}$ height, a horizontal wind gust in $x$--direction hits the MAV. The wind increases from $0$ to $10 \si{\metre\per\second}$ and is modeled as stationary stochastic process as in equation \ref{eq:wind_state_space}. The state measurement is corrupted by noise.

\begin{figure}
\centering
\subfloat[][{Position in 3D}]{
\includegraphics{\folder/tikzfigures/helix_wind_3d_LQRI.tikz}
\label{fig:lqri_helix_3d}}
\qquad
\subfloat[][{Position top view}]{
\includegraphics{\folder/tikzfigures/helix_wind_xy_LQRI.tikz}
\label{fig:lqri_helix_xy}}
\caption{Helix experiment with a $10 \si{\metre\per\second}$ wind gust in $x$--direction for $5 \si{\metre} \leq z \leq 15 \si{\metre}$ and the LQRI.}
\label{fig:lqri_helix}
\end{figure}

The Firefly follows the helix reference precisely but with some delay, as expected.

In the top view \ref{fig:lqri_helix_xy} it is visible that the controller takes some time to compensate the wind. The Firefly deviates as much as $16 \si{\centi\metre}$ from the reference trajectory and takes about $5 \si{\second}$ to fully return to the reference when the wind changes.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% MPC
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{MPC} 
Model predictive control is an effective control technique to deal with multivariable constrained control problems. Instead of solving an infinite horizon optimal control problem like LQR, MPC solves a finite horizon problem in a repeated fashion. 

At every sampling time step $t$ a $N$--step open-loop optimal control problem (OCP) is solved. The solution of the first step is then applied as a control input $u_t$ and the rest is dismissed. At the next time step $t+T_s$ the problem is initialized with the current state $x_{t+T_s}$ and the open-loop optimal control procedure is repeated to find $u_{t+T_s}$. This iterative control technique is also referred to as receding horizon control (RHC). An introduction on the topic and theory can be found in Morari's and Lee's essay \cite{Morari1999} or Maciejowski's book \cite{Maciejowski2002}.

The main advantage of model predictive control is the incorporation of constraints on inputs and states. This allows you to meet safety constraints and at the same time push the system to the limits. Second, due to its predictive nature, the controller has automatic feed-forward behavior. Given the OCP is convex, e.g. linear system, quadratic cost and box constraints, very efficient solvers are available which can calculate the solution online. The solution is optimal with respect to the formulation. Additionally, linear MPC has some advances in theory, like stability guarantees and offset-free control. Given a linear system, the control problem is straight forward to set up.

\subsection{Problem Formulation}
We will present an offset-free, reference tracking, linear MPC scheme. Steady-state offset-free control for constant references is achieved by augmenting the system dynamics with a constant disturbance as proposed by Pannocchia and Rawlings and extended by Maeder \cite{Pannocchia2003a,Maeder2009}. The disturbance is estimated using a Luenberger observer. 

Reference tracking is done by finding steady-state inputs and states, that are sufficient to meet the control target. The object of the OCP is to minimize the distance between all future states and inputs and their corresponding steady-state value. We choose a quadratic cost function. Note that all systems in this section are discrete-time with a sampling time of $T_s = 0.01\si{\second}$. 

Augmenting the system with input and ouput disturbances $d_k$ and tracked measurement outputs $z_k$ we obtain an extended state-space model. The dimensions are $x\in\mathbb{R}^{n_x}$, $u\in\mathbb{R}^{n_u}$, $w\in\mathbb{R}^{n_w}$, $d\in\mathbb{R}^{n_d}$, $y\in\mathbb{R}^{n_y}$ and $z\in\mathbb{R}^{n_z}$. The system contains the wind feed-forward matrix $B_w$.
\begin{align}
x_{k+1} &= A x_k + B u_k + B_w w_k + B_d d_k \label{eq:MPC_dt}\\
d_{k+1} &= d_k \nonumber \\ 
y_{k} &= C x_k + C_d d_k \nonumber \\
z_k &= H y_k 
\end{align}

For our multirotor the open-loop optimal control problem formulates as following:

\begin{align}
&\min_{u(\cdot),x(\cdot)}
& & ||x_N-\bar{x}_t||_P^2 + \sum_{k=0}^{N-1} ||x_k - \bar{x}_t||_Q^2 + ||u_k - \bar{u}_t||_R^2  \nonumber\\
& \text{s.t.} 
& & x_{k+1} = A x_k + B u_k + B_w w_k + B_d d_k, & k = 0, \ldots, N-1 \nonumber\\
& & & w_{k+1} = w_k  & k = 0, \ldots, N-1 \nonumber\\
& & & d_{k+1} = d_k, & k = 0, \ldots, N-1 \nonumber\\
& & & x_k \in \mathcal{X}, \; u_k \in \mathcal{U}, & k = 0, \ldots, N-1 \nonumber\\
& & & x_N \in \mathcal{X}_f \nonumber\\
& & & x_0 = \hat x (t), \; d_0 = \hat d(t), \; w_0 = \hat w(t) \label{eq:mpc_opti}
\end{align}

As in the LQRI, we require $Q\succeq0$, $P\succeq0$ and $R\succ0$. We will choose $P$ to solve the DARE. This mimics unconstrained infinite horizon control at the end of the horizon and guarantees stability for the closed-loop linear system, if the terminal set is invariant. The wind and augmented disturbances are assumed constant.

The steady-state targets $\bar{x}_t$ and $\bar{u}_t$ are calculated at every sampling time $t$, if possible for all $N$ future reference points. They are the solution of the following least-squares problem, which is established by solving system \ref{eq:MPC_dt} for $x_{k+1}=x_k=\bar{x}_t$, $u_k = \bar{u}_t$ and $z_k = r(t)$ with $r(t)$ being the current reference position and velocity. The inverse of the left-hand side matrix $M^{-1}$ can be obtained offline.
\begin{align}
\underbrace{\begin{bmatrix}
A-I & B \\
HC & 0 
\end{bmatrix}}_{M:=}
\begin{bmatrix}
\bar{x}_t \\
\bar{u}_t
\end{bmatrix}
=
\begin{bmatrix}
-B_w \hat{w}(t) - B_d \hat{d}(t)\\
r(t) - H C_d \hat{d}(t) \label{eq:steady_state_ls}
\end{bmatrix}
\end{align}
$\hat{w}(t)$ is the wind velocity vector estimated at the current time sample. $\hat{d}(t)$ and $\hat x (t)$ are the currently estimated disturbances and analogously estimated states. The estimator is a Luenberger observer, estimating the disturbance and state at every sample time. Instead, for example, a Kalman filter could have been applied as well. The estimator is updated using the following equation. $u(t)$ is the previously calculated and applied optimal control input. $x(t)$ is the currently measured state.
\begin{align}
\begin{bmatrix}
\hat{x}(t+1) \\ \hat{d}(t+1)
\end{bmatrix}
&=\left(
\begin{bmatrix}
A & B_d \\
0 & I
\end{bmatrix}
- L
\begin{bmatrix}
C & C_d
\end{bmatrix}
\right) \begin{bmatrix}
\hat{x}(t) \\ \hat{d}(t)
\end{bmatrix}
+
\begin{bmatrix}
B & B_w \\
0 & 0
\end{bmatrix}
\begin{bmatrix}
u(t) \\ \hat{w}(t)
\end{bmatrix}
+
L C x(t) \label{eq:mpc_obsv_update}
\end{align}

The observer gain $L$ is computed offline using regular pole placement methods for the system. Here, this is done using MATLAB's \texttt{place} command. The dual of the closed-loop feedback problem is described by the observer error dynamics \ref{eq:mpc_obsv_err} of the augmented system, which has to be observable. The poles are chosen, such that the error dynamics settle fast enough, but sensor noise is not amplified too much. We set them around $5\si{\radian\per\second}$. 
\begin{align}
\begin{bmatrix}
A & B_d \\
0 & I
\end{bmatrix}
- L
\begin{bmatrix}
C & C_d
\end{bmatrix} \label{eq:mpc_obsv_err}
\end{align}

To guarantee offset-free MPC, we pick $n_d$, the number of disturbances, equal to the number of outputs $n_y$. According to Maeder \cite{Maeder2009}, the augmented system \ref{eq:MPC_dt} is observable if and only if $(C,A)$ observable and
\begin{align}
\det \begin{bmatrix}
A-I & B_d \\ C & I 
\end{bmatrix} = det(A-I-B_dC) \neq 0 \label{eq:mpc_obsv_cond}
\end{align}

\subsection{Implementation}
In this subsection we discuss the implementation of the MPC and how the previously derived dynamics apply to the problem formulation.

The MPC can be summarized in the following steps:
\begin{enumerate}
\item initialization: compute $P$, $L$, $M^{-1}$
\item repeat at every sample time
\begin{enumerate}
\item update state and disturbance estimation \ref{eq:mpc_obsv_update} \label{enum:mpc_start}
\item calculate $N$ desired steady-state inputs and states \ref{eq:steady_state_ls}
\item solve optimization problem \ref{eq:mpc_opti}
\item apply first control input to system \label{enum:mpc_finish}
\end{enumerate}
\end{enumerate}

\subsubsection{CVXGEN}
The optimization problem \ref{eq:mpc_opti} is the computationally limiting part in MPC, as a convex optimization problem has to be solved. One can handle this problem by explicitly solving \ref{eq:mpc_opti} for all possible constraint and state combinations and looking up the control law, which is piecewise affine. Or one solves the OCP online, which we choose.

Convex optimization problems can be solved very efficiently using the code generation software for convex optimization CVXGEN by Mattingley and and Boyd \cite{Mattingley2010}. Unlike regular parser, hard-coded solvers solve optimizations a lot faster. They exploit the fact that the problems dimensions and structure is known a priori. For example, they take care of transformations in advance and allocate memory in an initialization phase of the running program.

For code generation, one can simply write down the problem similar to \ref{eq:mpc_opti} in the CVXGEN interface. The software then automatically generates hard-coded c-code and a MATLAB MEX interface with the solver. This solver then can be called from within MATLAB using \texttt{csolve}.

The code for generating the solver is displayed in listing \ref{code:cvxgen} in the appendix. The dimensions and the prediction horizon have to be fixed. For the proposed linear system \ref{eq:lin_sys_dt}, we have $n_x=n_d=10$ states and disturbances, $n_u=3$ control inputs and $n_w=2$ wind inputs. 

The number of states, control inputs, prediction horizon and constraints determines the size of the optimization problem. We choose a prediction horizon of $N=40$, which corresponds to looking $0.4\si{\second}$ ahead. For larger horizons, the optimal control problem becomes too large and the code can not be generated. All other parameters, like the system matrices, the current state and constraints, can be passed to the solver before calling \texttt{csolve}. Notice in the code, that we denoted the sparsity of the system matrices explicitly, which cut the computation time to half.

\subsubsection{System Matrices}
As for the LQRI, we consider the heading free linear system \ref{eq:lin_sys_dt}. We discretize the model  and assign it to the above defined MPC state-space system \ref{eq:MPC_dt}. Again notice, that the position and velocity in the state and the reference need to be converted into orientation-fixed frame. 
\begin{align}
A &\gets {\mathbf{A}} \\
B &\gets {\mathbf{B}} \\
B_w &\gets {\mathbf{B}}_w \\
C &\gets {\mathbf{C}} \\
x_k &\gets \mathbf{x}_{\mathcal{O},k} - \mathbf{x}_{\mathcal{O},ss}  \\
u_k &\gets \mathbf{u}_{\mathcal{O},k} - \mathbf{u}_{\mathcal{O},ss}  \\
u_k &\gets \mathbf{y}_{\mathcal{O},k} - \mathbf{y}_{\mathcal{O},ss}  \\
r_k &\gets \begin{bmatrix}
\mathbf{r}_{\mathcal{O},ref,k} \\
\mathbf{v}_{\mathcal{O},ref,k}
\end{bmatrix}
\end{align}

The MPC will have position and velocity tracking capabilities. Thus we choose the matrix $H$ accordingly.
\begin{align}
H &= \begin{bmatrix}
\mathbf{0}_{6\times4} & \mathbf{I}_6 
\end{bmatrix} 
\end{align}
\subsubsection{Weights}
Weighting the cost function has been done iteratively, simulating step experiments and adjusting the weights until a desired performance was achieved. Eventually we chose:
\begin{align}
Q &= \begin{bmatrix}
\mathbf{I}_4 & 0 & 0 \\
0 & 10\cdot\mathbf{I}_3 & 0 \\
0 & 0 & \mathbf{I}_3
\end{bmatrix}
R &= \begin{bmatrix}
0.001 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}
\end{align}
We penalize the deviation from the desired steady-state position a little more and decrease the penalty on the reference thrust. This weighting leads to a rather aggressive tuning.
\subsubsection{Disturbance Model}
\label{sec:mpc_dist}
As Maeder states in \cite{Maeder2009}, the simplest way to achieve offset-free control is to set the number of disturbances equal the number of outputs, $n_d=n_y=10$. The disturbance matrices $B_d$ and $C_d$ then have to be chosen such that the augmented system is observable (\ref{eq:mpc_obsv_cond} holds).

A common way is to model the disturbance as output disturbance with $C_d=\mathbf{I}$ and $B_d= \mathbf{0}$. However, this is only possible, if the plant has no integrators, which our plant has.

Therefore we model the disturbance as simple input disturbance.
\begin{align}
B_d = \mathbf{I}_{10} \\
C_d = \mathbf{0}_{10\times10}
\end{align}
Physically, this means, we have disturbance accelerations (forces and moments) and velocities acting on the system. The controller estimates these and adapts the inputs accordingly to compensate them.
\subsubsection{Constraints}
MPC has the great advantage to consider constraints on inputs and states explicitly in the problem formulation. One could for example use this feature for obstacle avoidance.

We will only use input constraints. For one thing, we want to keep the attitude bounded, such that it does not diverge too much from the linearization point or gets into regions of singular Euler angles. And for another, we limit the thrust within the capable regions given by the motors (see equations \ref{eq:T_min} and \ref{eq:T_max}).

\begin{align}
T_{min} \leq T_{ref} \leq T_{max} \\
\si{-30}{\degree} \leq \phi_{ref} \leq \si{30}{\degree} \\
\si{-30}{\degree} \leq \theta_{ref} \leq \si{30}{\degree}
\end{align}

\subsection{Simulation Results}
For validation of the controller's quality, we simulate the same experiments as for the LQRI using the MATLAB simulator. First, we will determine the performance. Then we will check its ability to follow dynamic references. Next we will see how it reacts to measurement noise. Finally, a wind experiment is performed.

\subsubsection{Performance}
For performance examination, we run a noise-free step response experiment. The reference is set $1 \si{\metre}$ away from the MAV into $x$--direction. The MPC finds appropriate tilting and thrust signals for the multirotor to move to this position. Figure \ref{fig:mpc_step} depicts the outcome of this experiment.
\begin{figure}
\centering
\subfloat[][{Position output}]{
\includegraphics{\folder/tikzfigures/step_response_out_MPC.tikz}
\label{fig:mpc_step_out}}
\qquad
\subfloat[][{Control input}]{
\includegraphics{\folder/tikzfigures/step_response_in_MPC.tikz}
\label{fig:mpc_step_in}}
\caption{Simulated unit step response of the MPC controlled Firefly. The MAV has to fly from hovering $1\si{\metre}$ ahead.}
\label{fig:mpc_step}
\end{figure}

In comparison to the LQRI, the MPC is tuned more aggressively. In the first interval of the control inputs \ref{fig:mpc_step_in}, the reference pitch is set to the maximum ($30\si{\degree}$) to accelerate into $x$--direction. Then, when the target is close enough, the pitch reference is reversed in order to come to a stop at $x=1\si{\metre}$.

Hereby, the linear control law is switched from the constrained to the unconstrained case. The unconstrained linear control law corresponds to the standard linear quadratic regulator law, as the final penalty has been chosen to be the solution of the algebraic Riccati equation.

The step response has no overshoot, a $10$ to $90\si{\percent}$ rise time of $0.82 \si{\second}$ and a $2\si{\percent}$ settling time of $1.73 \si{\second}$. With this, it has a better performance than the LQRI.

The controller achieves offset free tracking of constant references. Modeling errors are estimated as constant input disturbances as stated in the previous section \ref{sec:mpc_dist}. The estimated disturbances are depicted in figure \ref{fig:mpc_step_dist}. Two things stand out.

\begin{figure}
\centering
\includegraphics{\folder/tikzfigures/step_response_dist_MPC.tikz}
\caption{Disturbance estimation for the noise-free unit step response of the MPC. $d_x$,$d_y$,$d_z$ in $[\si{\metre\per\second}]$, $d_{dx}$,$d_{dy}$,$d_{dz}$ in $[\si{\metre\per\second\per\second}]$, $d_\phi$,$d_\theta$ in $[\si{\radian\per\second}]$, $d_{1/8d\phi}$,$d_{1/8d\theta}$ in $[\si{\radian\per\second\per\second}]$}
\label{fig:mpc_step_dist}
\end{figure}

First, mostly disturbances in acceleration occur, e.g. $d_{dz}$. Physically, these disturbances are forces and moments acting on the MAV that are not modeled. For example in the first two seconds a relatively large disturbance force in $z$--direction is estimated, dragging the Firefly down. This disturbance probably comes from the drag force, which $z$--component is lost during linearization and the unmodelled allocation map, which reduces the overall thrust when pitching.

Second, there is a constant remaining force into $z$--direction at steady-state. This force is then compensated by the controller and thus it achieves offset-free reference tracking.

\subsubsection{Delay}
To see, how well the MPC can deal with dynamic references, we run the sinusoid experiment as for the LQRI on a noise-free plant. The Firefly has to go back and forth $1\si{\metre}$ twice within $6 \si{\second}$. The controller has knowledge about the next $N=40$ future reference positions and velocities and tries to minimize the distance to them. The resulting output is depicted in figure \ref{fig:mpc_sine}.

The MAV catches up with the desired position and velocity already on the first segment and then follows the sine wave closely. Compared with the LQRI it has the advantage of looking $0.4\si{\second}$ into the future, adapting its inputs accordingly. 

However, as the desired trajectory is quite demanding in terms of frequency, the MPC does not reach the full amplitude either. 

\begin{figure}
\centering
\includegraphics{\folder/tikzfigures/sine_response_out_MPC.tikz}
\caption{Simulated sine trajectory experiment  of the MPC controlled Firefly. The MAV has to fly back and forth $1\si{\metre}$ starting from hovering.}
\label{fig:mpc_sine}
\end{figure} 

\subsubsection{Noise}
To see the MPC's sensitivity to noise, we run the step experiment again, but this time the state measurement is delayed and disturbed by additive white noise. Figure \ref{fig:mpc_step_noisy} shows the response and control input. Figure \ref{fig:mpc_step_dist_noisy} shows the estimated constant disturbances for offset-free control.

The measurement noise is entering the system in two ways. For one thing, the optimal control problem \ref{eq:mpc_opti} gets initialized with the current state estimation. And for another, the state measurement is used for estimating the disturbances in the measurement update equation \ref{eq:mpc_obsv_update}.

Both effects have direct influence on the control input. As the MPC is tuned quite performance optimized, the noise leads to jerk, as the control input is scrambled (see figure \ref{fig:mpc_step_in_noisy}). However, the control target is still achieved as can be seen in the experiment output \ref{fig:mpc_step_out_noisy}. No situations of instability have been observed.


The disturbances, which should be zero as in the noise-free experiment \ref{fig:mpc_step_dist}, now show some significant reaction \ref{fig:mpc_step_dist_noisy}. The Luenberger observer gain $L$ governing the observer error dynamics \ref{eq:mpc_obsv_err} does not only lead to a relatively fast converging disturbance observer, but also introduces measurement noise to the estimation. Therefore the gain can not be chosen too large and in future works, a Kalman filter may be a better choice.

To reduce the jerk effect in the response, the controller could be tuned less aggressive.

\begin{figure}
\centering
\subfloat[][{Position output}]{
\includegraphics{\folder/tikzfigures/step_response_out_MPC_noisy.tikz}
\label{fig:mpc_step_out_noisy}}
\qquad
\subfloat[][{Control input}]{
\includegraphics{\folder/tikzfigures/step_response_in_MPC_noisy.tikz}
\label{fig:mpc_step_in_noisy}}
\caption{Unit step response MPC with noisy state and wind measurements.}
\label{fig:mpc_step_noisy}
\end{figure}

\begin{figure}
\centering
\includegraphics{\folder/tikzfigures/step_response_dist_MPC_noisy.tikz}
\caption{Disturbance estimation for the MPC's noisy step experiment.}
\label{fig:mpc_step_dist_noisy}
\end{figure}

\subsubsection{Wind}
Unlike the LQRI, the MPC has wind feed-forward. We run the helix experiment with wind gust as above.

The MAV has to climb up linearly from $0$ to $20 \si{\metre}$ at $0.15 \si{\metre\per\second}$ in a helix like manner. While climbing up it has to complete $4$ circles with a diameter of $4\si{\metre}$. The whole experiment takes $1 \si{\minute}$. 

From $5$ to $15 \si{\metre}$ height, a horizontal wind gust in $x$--direction hits the MAV. The wind increases from $0$ to $10 \si{\metre\per\second}$ and is modeled as stationary stochastic process as in equation \ref{eq:wind_state_space}. The state and wind measurement is corrupted by noise and delayed.

\begin{figure}
\centering
\subfloat[][{Position in 3D}]{
\includegraphics{\folder/tikzfigures/helix_wind_3d_MPC.tikz}
\label{fig:mpc_helix_3d}}
\qquad
\subfloat[][{Position top view}]{
\includegraphics{\folder/tikzfigures/helix_wind_xy_MPC.tikz}
\label{fig:mpc_helix_xy}}
\caption{Helix experiment with a $10 \si{\metre\per\second}$ wind gust in $x$--direction for $5 \si{\metre} \leq z \leq 15 \si{\metre}$ and the MPC}
\label{fig:mpc_helix}
\end{figure}

The MPC controlled multirotor follows the reference trajectory very well. Figure \ref{fig:mpc_helix_3d} shows the position. One can observe how the MAV is deviated from its track at $z=5\si{\metre}$ and $z=15\si{\metre}$, when the wind starts and ends. 

Even though, the wind measurements come with a delay of $0.1 \si{\second}$, the MPC is still a lot faster in compensating the drag due to the gust than the LQRI. The MPC controlled Firefly only deviates as much as $5\si{\centi\metre}$ from the reference trajectory, when the wind sets in (see top view \ref{fig:mpc_helix_xy}).% Still it needs about $4\si{\second}$ to completely return to the reference.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% NMPC
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{NMPC} 
Nonlinear MPC has the same principle as linear MPC. At every time step, a finite horizon open-loop optimal control problem is solved. The first input of the optimal input is applied to the system until the next sampling instant. Then the next finite horizon open-loop optimal control problem is solved.

Like MPC, NMPC can handle constraint systems, allowing the controller to push the system to the limits. Also, NMPC is naturally feed-forwarding, as it predicts the system states into the future and finds control inputs given this knowledge. 

Unlike MPC, however, the solution of the optimal control problem is not necessarily globally optimal. While linear MPC uses the advantages of convex optimization, the nonlinear counterpart is prone to local minima. Besides, guaranteeing stability for NMPC is more difficult. 

An introduction to the topic can be found in Allgöwer and Johansen \cite{Allgower2004,Johansen2011}. More advanced strategies and future outlooks can be found in Findeisen's, Allgöwer's and Biegler's lecture notes on NMPC \cite{Findeisen2007}.

We will derive a potentially simple reference-tracking offset-free controller for the nonlinear dynamics proposed in the state equations \ref{eq:state_diff}. For guidance and code generation we used the open-source Automatic Control and Dynamic Optimization (ACADO) toolbox written by Diehl, Ferreau, Houska, Vukov and others \cite{Houska2011,Vukov2013}.

Although Fontes \cite{Fontes2001} provides a technique to guarantee closed-loop stability, our controller will have no proof on stability. The approach by Fontes relies on finding a terminal penalty and terminal region such that a Lyapunov function can be found, that guarantees stability. We instead totally rely on a range of simulations. 

\subsection{Problem Formulation}
We consider the following continuous time optimal control problem (OCP).
\begin{align}
&\min_{x(\cdot),u(\cdot)} &&\int_{t}^{t+NT_s} \left( ||x(\tau)-x_{ref}(\tau)||_Q^2 + ||u(\tau)-u_{ref}(\tau)||_R^2 \d \tau \right)  \nonumber \\
&&&+ ||x(t+NT_s)-x_{ref}(t+NT_s)||_P^2, \nonumber \\
&s.t. &&\dot{x}(\tau) = f(x(\tau),u(\tau)), \nonumber \\
&&&\dot{w}(\tau) = 0, \nonumber \\
&&&\dot{\psi}(\tau) = 0, \nonumber \\
&&&x(\tau) \in \mathcal{X}, \; u(\tau) \in \mathcal{U}, \quad \forall\tau\in\left[t,t+NT_s\right], \nonumber \\
&&&x(t) = \hat{x}(t),\; w(t) = \hat{w}(t), \; \psi(t) = \hat{\psi}(t).  \label{eq:nmpc_opt_prob}
\end{align}
$N$ is the time horizon, $T_s$ is the sampling time, $t$ is the current sampling instant time, $Q\succeq0$ is the state penalty, $R\succ0$ is the input penalty, $P\succeq0$ is the terminal state penalty, $f(\cdot)$ is the differential equation governing the system, $\mathcal{X}$ is the unconstrained state space, $\mathcal{U}$ is the constrained input space, $\hat{x}(t)$ is the state, $\hat{w}(t)$ the wind and $\hat{\psi}(t)$ the heading measurements at the current sampling instant.

In order to achieve offset-free control at steady state, the state $x(t)$ is augmented with an integrator state $e(t)$.
\subsection{Implementation}
The NMPC is implemented using MATLAB. The solver to the OPC is generated offline using the ACADO toolkit. The solver is then called at every sample instant. The running program can be summarized into the following steps:

\begin{enumerate}
\item initialization: compute $P$, set warm start
\item repeat at every sample time
\begin{enumerate}
\item set online data (wind, heading)
\item set reference
\item set warm start
\item solve OPC
\item save future inputs and outputs
\item update integrator
\item apply first control input
\end{enumerate}
\end{enumerate}
\subsubsection{ACADO}
For generating the solver we use the ACADO toolbox. The toolbox has a MATLAB interface that simplifies the creation. Vukov gives a good introduction to the solver \cite{Vukov2013}.The OCP \ref{eq:nmpc_opt_prob} is discretized using multiple shooting as presented by Bock \cite{bock1984multiple}. The discrete non-linear least square optimal control problem is then solved using a generalized Gauss-Newton method, which was elaborated by Bock as well \cite{Bock1983}. Diehl optimized this method for MPC. The real-time iteration (RTI) scheme \cite{Diehl2005} uses the control inputs and states from the previous optimization run as a new linearization point and following that only one Newton-iteration is necessary per sampling instant.

ACADO supports different solvers for the discretized non-linear least square OCP. By default, ACADO uses the dense linear algebra solver qpOASES written by Ferreau \cite{Ferreau2014}. It uses a condensing based RTI scheme, which reduces the number of optimization variables and performs well for short prediction horizons.

In MPC long prediction horizons are desired. For our problem we will have $N=100$. A sparse quadratic program solution is more efficient. Recently Frasch released a new open-source sparse solver called qpDUNES \cite{Frasch}. It uses a mix of the structure exploitation of interior point methods and warm-starting capabilities of active set methods. The solving time for the hexacopter OCP \ref{eq:MPC_dt} was cut down to a half using the sparse solver instead of the condensed solver.

Other solvers supported by ACADO are HPMPC by Frison \cite{www:hpmpc} and FORCES by Dimahidi \cite{www:forces}. They were not used because either they were not fully supported by the MATLAB interface or required a license.

Further we optimized the ACADO solver settings to achieve a computation time as small as possible (see chapter). We use a second order implicit Runge-Kutta method for integration instead of a fourth order method, reduced the number of integrator iterations to two (5 by default) and used $N=100$ integrator steps.

The code for creating the solver is printed in listing \ref{code:acado}.
\subsubsection{System Dynamics}
We can directly use the derived non-linear system dynamics \ref{eq:state_diff}. We will consider the positions and translational velocities in world-fixed coordinates and the angles and angular rates in orientation-fixed coordinates. The state however, is augmented by an integrator.
\begin{align}
x &= \begin{bmatrix}
\mathbf{x} \\
\mathbf{e}
\end{bmatrix} \\
u &= \mathbf{u} \\
w &= \mathbf{w} \\
f(x(t),u(t)) &= \begin{bmatrix}
f(\mathbf{x},\mathbf{u},\mathbf{w}) \\
\ddt \mathbf{e}
\end{bmatrix} \label{eq:ocp_dyn}
\end{align}
The dynamics of the wind and the heading are actually not modeled as in the OCP \ref{eq:nmpc_opt_prob}, but rather fed to the NMPC as a constant $N\times4$ array. This can be done in ACADO using the \texttt{OnlineData} data type.

In the code generation \ref{code:acado} the system dynamics are explicitly separated into purely linear attitude dynamics and non-linear translational and error dynamics. Acado takes advantage of this structure as explained by Quirynen \cite{Quirynen2013}. The solving time has been reduced significantly $(2\si{\milli\second})$ for this problem when using the linear subsystem exploitation.
\subsubsection{Integrator}
The integrator follows the dynamics
\begin{align}
\ddt \mathbf{e}_{real}(\tau) &= \mathbf{r}_{ref} - \mathbf{r(\tau)},  \label{eq:e_dt} \\
e_{real}(t) &= e_{real}(t), \nonumber\\
-e_{max} \mathbf{1} &\leq e_{real}(t) \leq e_{max}  \mathbf{1} \nonumber.
\end{align}
It is limited by the upper and lower value $e_{max}=0.2$ in order to prevent the system from wind-up. However, this constraint can not straight forward be implemented in the ACADO differential equation. 

If it was just set as a constraint, the problem immediately goes infeasible, if the set point is to far away from the current position. Imagine for example the MAV being away $x_{ref}-x(t) = 1 \si{\metre}$ away from the reference position. If the MAV can not make it to the reference within the prediction horizon, the integral term will strictly monotonously grow, exceed the maximum value, and the optimization problem is infeasible.

To prevent this, we do not constraint the error term hard, but rather window its differential equation. If the error term is outside the boundary, the growth will be set to zero. We impose a rectangular window on the error function \ref{eq:e_dt}. Because a rectangular window function is discontinuous, we will rather approximate the step functions generating the window by a combination of logistic functions \ref{eq:logistics_window}. Such a window is depicted in figure \ref{fig:logistics_window}.
\begin{align}
W(e_x) &= \frac{L}{1+\exp{(-k(e_x+e_{max}))}}  - \frac{L}{1+\exp{(-k(e_x-e_{max}))}}\label{eq:logistics_window}
\end{align}
\begin{figure}
\centering
\includegraphics{\folder/tikzfigures/window.tikz}
\caption{Approximated rectangular window as combination of logistics functions with $e_{max}=\num{0.05}$, $L=1$, $k=\num{e2}$}
\label{fig:logistics_window}
\end{figure}
Thus, the integrator dynamics in \ref{eq:ocp_dyn} are modeled for the non-linear OCP:
\begin{align}
\ddt \mathbf{e}(\tau) &= \begin{bmatrix} 
W(e_x(\tau)) & 0 & 0 \\
0 & W(e_y(\tau)) & 0 \\
0 &  0 & W(e_z(\tau))
\end{bmatrix}
\left(\mathbf{r}_{ref} - \mathbf{r(\tau)} \right), \\
\mathbf{e}(t) &= \mathbf{e}_{real}(t) \nonumber.
\end{align}
\subsubsection{Reference}
The reference $x_{ref}$ inputted into the acado solver consists of an $N+1\times13$ array which is updated at every sample instant with the very next desired position and if possible all next $N$ future reference positions and velocities. With the controller having knowledge about the desired future position and velocity, feedforward is granted. If they are not known, the position reference will just be constant over the whole prediction horizon and the velocity reference will be set to zero. 

The reference attitude is set to zero, which causes some "damping", depending on the weight on the attitude error term. The integrator reference is set to zero, to make the system drive the integrator to zero.
\begin{align}
x_{ref} = \begin{bmatrix}
0 & 0 & 0 & 0 & \mathbf{r}_{ref,t} & \mathbf{v}_{ref,t} & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & \mathbf{r}_{ref,t+T_s} & \mathbf{v}_{ref,t+T_s} & 0 & 0 & 0 \\
 &  &  &  & \vdots &  &  &  &  \\
0 & 0 & 0 & 0 & \mathbf{r}_{ref,t+NT_s} & \mathbf{v}_{ref,t+NT_s} & 0 & 0 & 0 
\end{bmatrix}
\end{align}

The reference input $u_{ref}$ consists of a $N\times3$ array of the steady state hovering inputs. With according penalty on the offset from hovering, the optimizer is trying to let the MAV not deviate to much from hovering state. This leads to some damping in the controller.
\begin{align}
u_{ref} = \begin{bmatrix}
mg & 0 & 0 \\
mg & 0 & 0 \\
  & \vdots &  \\
mg & 0 & 0 
\end{bmatrix}
\end{align}
\subsubsection{Weights}
The cost function penalizes the difference between desired state and input and actual state and input over the horizon. We weight this deviation using the following diagonal matrices:
%\begin{align}
%Q = \begin{bmatrix}
%\num{e-1} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
%0 & 10^{-1} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
%0 & 0 & 10^{-1} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
%0 & 0 & 0 & 10^{-1} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
%0 & 0 & 0 & 0 & 10^{-1} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
%0 & 0 & 0 & 0 & 10^{-1} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
%0 & 0 & 0 & 0 & 10^{-1} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 
%\end{bmatrix}
%\end{align}
\begin{align}
&Q = \begin{bmatrix}
Q_{att} & 0 & 0 & 0 \\
0 & Q_{r} & 0 & 0 \\
0 & 0 & Q_{v} & 0 \\
0 & 0 & 0 & Q_{e}
\end{bmatrix},\\
&Q_{att}= \num{e-1} I_4  \quad  Q_{r} = \num{e1} I_3 \quad
Q_{v} = \num{e-1} I_3  \quad Q_{e} = \num{e1} I_3 \nonumber \\
&R = \begin{bmatrix}
\num{e-1} & 0 & 0 \\
0 & \num{3e-1} & 0 \\
0 & 0 & \num{3e-1}
\end{bmatrix} \label{eq:nmpc_input_penalty}
\end{align}
The large gain in the position $Q_{r}$ and integrator penalty $Q_{e}$ amplifies the tracking behavior. The rather smaller other gains will lead to some damping, respectively subordinative velocity tracking in case of $Q_{v}$.

The final penalty $P$ is the solution of the continuous time algebraic Riccati equation \ref{eq:care} of the linearized system \ref{eq:lin_sys_dt}. The solution is found using MATLAB's \texttt{lqi} function.
\begin{align}
A^TP+PA-PBB^TP+Q=0\label{eq:care}
\end{align}
While this is not totally correct, as the linearized system uses an orientation-fixed coordinate system for the translational dynamics, it still gives an approximation for the infinite horizon OCP solution at the final time step.
\subsubsection{Constraints}
Again, we will only use input constraints. We want to keep the attitude bounded, such that it does not diverge too much from the linearization point (our attitude dynamics are still linearized around hovering) or even gets into regions of singular Euler angles. And we limit the thrust within the capable regions given by the motors (see equations \ref{eq:T_min} and \ref{eq:T_max}. However, we allow a little more tilt than in the linear MPC.

\begin{align}
T_{min} \leq T_{ref} \leq T_{max} \\
\si{-45}{\degree} \leq \phi_{ref} \leq \si{45}{\degree} \\
\si{-45}{\degree} \leq \theta_{ref} \leq \si{45}{\degree}
\end{align}

\subsubsection{Initialization and Warm Start}
At every sample instant we will initialize the OCP \ref{eq:nmpc_opt_prob} with the previously determined $N$ optimal states and inputs. This will lead to convergence of the NMPC loop according to Diehl's work on the real-time iteration (RTI) scheme \cite{Diehl2005}.

At the very first sampling instant, the OCP state vector is initialized with zero attitude and the desired position and velocity. The optimal input is initialized with hovering.
\subsection{Simulation Results}
We run the same experiments as for the other two controllers to validate the NMPC's performance. These include a nominal step response, following a sinusoid reference, a noisy step experiment and finally a wind experiment. All of them are simulated in the MATLAB simulator with the same parameters as before. 

\subsubsection{Performance}
For performance examination, we run a noise-free step response experiment. The reference is set $1 \si{\metre}$ away from the MAV into $x$--direction. The NMPC finds appropriate tilting and thrust signals for the multirotor to move to this position. Figure \ref{fig:mpc_step} depicts the outcome of this experiment.
\begin{figure}
\centering
\subfloat[][{Position output}]{
\includegraphics{\folder/tikzfigures/step_response_out_NMPC.tikz}
\label{fig:nmpc_step_out}}
\qquad
\subfloat[][{Control input}]{
\includegraphics{\folder/tikzfigures/step_response_in_NMPC.tikz}
\label{fig:nmpc_step_in}}
\caption{Unit step response for the NMPC with the nominal model}
\label{fig:nmpc_step}
\end{figure}

Like the MPC, the NMPC tilts towards the target hitting the constraints of $45\si{\degree}$, and then reverses the direction to slow down. The NMPC is tuned more aggressive, such that it has a more bang-bang like control input. 

Due to its integral part, the MAV overshoots the setting point by $7\si{\centi\metre}$ and then settles down to the steady-state value. It achieves the fastest $10$ to $90\si{\percent}$ rise time of $0.46 \si{\second}$, but has due to its integrator only a $2\si{\percent}$ settling time of $1.71 \si{\second}$, which is about the MPC settling time.

\subsubsection{Delay}
Like the MPC, the NMPC has feed-forward capacities and thus is able to follow dynamic trajectories without delay. We repeat the sinusoid experiment in which the Firefly has to go back and forth $1\si{\metre}$ twice within $6 \si{\second}$. The controller has knowledge about the next $N=100$ ($1\si{\second}$) future reference positions and velocities and tries to minimize the distance to them. The resulting output is depicted in figure \ref{fig:nmpc_sine}.

The MAV has to catch up with the reference position and then follows the reference quite closely. Due to its faster rise time, the NMPC performs best in reaching the target amplitude.

\begin{figure}
\centering
\includegraphics{\folder/tikzfigures/sine_response_out_NMPC.tikz}
\caption{Sine trajectory experiment NMPC}
\label{fig:nmpc_sine}
\end{figure} 

\subsubsection{Noise}
While the NMPC is the fastest proposed controller, it is not more sensitive to noise than the MPC controller. Again we run the step experiment augmented with measurement noise and delay, now with the NMPC. Figure \ref{fig:nmpc_step_noisy} shows the response and control input. 

The measurement noise is entering the system in the initialization of the OCP \ref{eq:nmpc_opt_prob}. The noise leads to significant jumps in the input signal \ref{fig:nmpc_step_in_noisy}. The control target, however, is still being reached and the NMPC has not faces instability in any experiment.

Still one should consider increasing the penalties on the input \ref{eq:nmpc_input_penalty} taking the controller to the real world.

\begin{figure}
\centering
\subfloat[][{Position output}]{
\includegraphics{\folder/tikzfigures/step_response_out_NMPC_noisy.tikz}
\label{fig:nmpc_step_out_noisy}}
\qquad
\subfloat[][{Control input}]{
\includegraphics{\folder/tikzfigures/step_response_in_NMPC_noisy.tikz}
\label{fig:nmpc_step_in_noisy}}
\caption{Unit step response NMPC with noisy state measurements}
\label{fig:nmpc_step_noisy}
\end{figure}


\subsubsection{Wind}
Like the MPC, the NMPC has wind feed-forward capabilities. We run the helix experiment with wind gust as above.

The MAV has to climb up linearly from $0$ to $20 \si{\metre}$ at $0.15 \si{\metre\per\second}$ in a helix like manner. While climbing up it has to complete $4$ circles with a diameter of $4\si{metre}$. The experiment's total time is $1 \si{\minute}$. 

From $5$ to $15 \si{\metre}$ height, a horizontal wind gust in $x$--direction hits the MAV. The wind increases from $0$ to $10 \si{\metre\per\second}$ and is modeled as stationary stochastic process as in equation \ref{eq:wind_state_space}. The state measurement is corrupted by noise.

\begin{figure}
\centering
\subfloat[][{Position in 3D}]{
\includegraphics{\folder/tikzfigures/helix_wind_3d_NMPC.tikz}
\label{fig:nmpc_helix_3d}}
\qquad
\subfloat[][{Position top view}]{
\includegraphics{\folder/tikzfigures/helix_wind_xy_NMPC.tikz}
\label{fig:nmpc_helix_xy}}
\caption{Helix experiment with a $10 \si{\metre\per\second}$ wind gust in $x$--direction for $5 \si{\metre} \leq z \leq 15 \si{\metre}$ and the NMPC}
\label{fig:nmpc_helix}
\end{figure}

The NMPC only gets deflected by $3\si{\centi\metre}$ from the reference trajectory when the wind changes and returns to the reference within $3.5 \si{\second}$. 